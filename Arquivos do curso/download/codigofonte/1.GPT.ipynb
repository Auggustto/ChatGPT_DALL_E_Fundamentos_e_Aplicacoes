{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1223d-1d4a-4c8b-9e2b-62fe8370f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9578b19b-d6d4-4a88-91af-d3c600877e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Transformers são uma forma de modelo de aprend\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "#chave de autenticação\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "response = openai.Completion.create(model=\"text-davinci-003\",prompt=\"Você pode explicar o que é um transformer no contexto de NLP?\")\n",
    "print(response.choices[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b06c9f5-0f7e-4a85-be12-47621e7f723f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Um transforma-house vá lê ordem MOTOR, tornando-se csgno e gerenciando-se bem como se fosse manual.\n",
      "\n",
      "Um transforma- CESNIL, forçando-se ao custo, pode quebra-espelhar a ordem MOTOR, gerenciando-se automático.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "#chave de autenticação\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-ada-001\",\n",
    "    prompt=\"Você pode explicar o que é um transformer no contexto de NLP?\",\n",
    "    max_tokens=1000    \n",
    "    )\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19a000fe-088c-42dc-969a-888032c51416",
   "metadata": {},
   "source": [
    "text-davinci-003\n",
    "Um transformer é um modelo de aprendizado de máquina profundo aplicado à tarefa de processamento de linguagem natural. Ele consiste em módulos funcionais de processamento de linguagem chamados de mecanismos de atenção, às vezes descritos como um novo modo de representar texto. Os transformadores usam esse mecanismo de atenção para capturar dependências à distância entre todos os elementos de entrada, incluindo de maneira eficaz a estrutura sintática e semântica que compõe a linguagem natural. Esta flexibilidade, juntamente com um poder de processamento de última geração, tornam os transformadores mais capazes que as redes neurais tradicionais para as tarefas de compreensão, tradução e classificação de texto."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d573812-535b-4ffe-97e5-da01aae31c5c",
   "metadata": {},
   "source": [
    "text-curie-001\n",
    "Um transformer é uma estrutura que permite aplicar um modelo para analisar dados em uma outra métrica, como o tempo ou o volume. Exemplos de transformadores usados no mundo da NLP são a função de regressão linear e a função de regressão logística."
   ]
  },
  {
   "cell_type": "raw",
   "id": "05e63681-38c0-4c0c-88cf-18635a68f214",
   "metadata": {},
   "source": [
    "text-babbage-001\n",
    "Um transformer é um mecanismo que permite transformar uma ideia, um pensamento, uma expectativa, numa realidade. Ele funciona com um princípio: a transformação é feita usando um parâmetro, e osaperspectiva altera as condições que afetam as outras."
   ]
  },
  {
   "cell_type": "raw",
   "id": "49417ebe-14a8-406a-b052-61bcd6f79b8f",
   "metadata": {},
   "source": [
    "text-ada-001\n",
    "Um transforma-house vá lê ordem MOTOR, tornando-se csgno e gerenciando-se bem como se fosse manual.\n",
    "Um transforma- CESNIL, forçando-se ao custo, pode quebra-espelhar a ordem MOTOR, gerenciando-se automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ce0a0b-a408-4725-95e6-51f47ad5e8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Um Transformer é um tipo de arquitetura de redes neurais que se destaca pela capacidade de processar sequências de texto de maneira profunda. Utiliza atenção mútua para se conectar entre as diferentes palavras em uma frase e, assim, melhorar a compreensão do contexto. Isso é útil para problemas de processamento de linguagem natural como classificação de sentenças, tradução, geração de resumo, etc.\n",
      "\n",
      "LSTM é uma abreviação de memória à longo prazo, é uma variante da rede neural recurrente, que torna possível e possível para as redes neurais se lembrarem de coisas mais antigas quando processam sequências ou frases. As LSTMs são usadas em problemas com memória a longo prazo como classificação de sentimento, tradução, reconhecimento de fala, etc.\n",
      "\n",
      "\n",
      "Transformers são mecanismos usados em Modelos de Processamento de Linguagem Natural (NLP, do inglês Natural Language Processing). Esses mecanismos permitem a abstração de contexto, atividades de tallagem de idioma e compreensão de frases complexas. Transformadores permitem que modelos NLP exibam melhores performances ao processar dados textuais.\n",
      "\n",
      "Uma Rede Neuronal Recorrente Longa de Curta Memória (LSTM, do inglês Long Short-Term Memory network) é uma tecnologia usada para modelar dependências sequenciais a longo prazo. A LSTM expande a capacidade limitada de memória da Rede Neural Recorrente para que o sistema possa entender o contexto. Isso permite que o modelo aprenda a lembrar informações passadas por longos períodos de tempo e, assim, prever o futuro. A LSTM é aplicada em muitos contextos de processamento de linguagem natural, como previsão de palavras em frases, tradução idioma natural e modelagem do comportamento dos usuários.\n",
      "\n",
      "\n",
      "Transformers são um tipo de modelo de aprendizado profundo para NLP que usa representações de dados baseadas em atenção. Essas representações permitem modelos a melhorar a qualidade da etapa de pré-processamento, aumentando a precisão das análises de texto.\n",
      "\n",
      "As Redes Neurais Recorrentes LSTM (Long Short-Term Memory) são modelos de processamento de linguagem natural projetados para aprender padrões de texto de comprimento variável. São bastante comumente usadas para problemas mais avançados de NLP, como previsão de sequência, codificação, compreensão de frases com contexto e classificação de sentimentos. Diferentemente do modelo padrão, onde as informações anteriores são periodicamente descartadas, uma LSTM mantém a memória da informação passada, melhorando sua capacidade de processar e codificar sequências de texto autenticas.\n",
      "\n",
      "\n",
      "Um transformer é uma arquitetura de redes neurais aplicada à NLP, essencialmente utilizada para aprender a codificar o significado das palavras em contextos específicos. A ideia por trás desse modelo é criar modelos para prever a próxima palavra a partir do contexto dado com redirecionamento automático usando atenção sobre entradas de texto arbitrariamente longas.\n",
      "\n",
      "Uma LSTM (Rede de memória de longo prazo) é um tipo de rede neural artificial projetada para aprender a codificar o significado das palavras em contextos específicos. É diferenciado das Redes Neurais Tradicionais pela capacidade de lembrar informações de vários fragmentos de texto diferentes, ficando mais próximos do processamento cognitivo que a humanidade usa para o processamento de linguagem natural (NLP). É usado em conversas em tempo real, e em várias aplicações de processamento de linguagem natural.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "#chave de autenticação\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Você pode explicar o que é um transformer no contexto de NLP? Você poderia também explicar o que é uma LSTM?\",\n",
    "    max_tokens=2000,\n",
    "    temperature=1,\n",
    "    n = 4\n",
    "    )\n",
    "\n",
    "for a in range(len(response.choices)):\n",
    "    print(response.choices[a].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36ece5c9-1296-4c1b-b657-e5789a8ae884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CARL EDWARD SAGAN foi um cientista planetário, astrônomo, astrobiólogo, astrofísico, escritor, divulgador científico e ativista norte-americano. Foi um grande defensor do ceticismo e do método científico. Estudou o efeito estufa em escala planetária, fund\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "texto = '''Carl Edward Sagan (Nova Iorque, 9 de novembro de 1934 — Seattle, \n",
    "        20 de dezembro de 1996) foi um cientista planetário, astrônomo, astrobiólogo, astrofísico, escritor, \n",
    "        divulgador científico e ativista norte-americano. Sagan é autor de mais de 600 publicações científicas\n",
    "        e também de mais de vinte livros de ciência e ficção científica. \n",
    "        Foi durante a vida um grande defensor do ceticismo e do uso do método científico. \n",
    "        Promoveu a busca por inteligência extraterrestre através do projeto SETI e instituiu o \n",
    "        envio de mensagens a bordo de sondas espaciais, destinadas a informar possíveis \n",
    "        civilizações extraterrestres sobre a existência humana. Mediante suas observações da atmosfera de Vênus, \n",
    "        foi um dos primeiros cientistas a estudar o efeito estufa em escala planetária.\n",
    "        Também fundou a organização não governamental Sociedade Planetária e foi pioneiro no ramo da exobiologia.\n",
    "        Sagan passou grande parte da carreira como professor da Universidade Cornell, onde foi diretor do laboratório\n",
    "        de estudos planetários. Em 1960 obteve o título de doutor pela Universidade de Chicago. '''\n",
    "\n",
    "#chave de autenticação\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Você pode fazer um resumo deste texto?\" + texto,\n",
    "    max_tokens=100,\n",
    "    temperature=1,\n",
    "    n = 1\n",
    "    )\n",
    "\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2547717c-394f-405b-9190-f65db556d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "O Rio de Janeiro fica no Brasil, na costa do Oceano Atlântico.\n",
      "\n",
      "\n",
      "O Rio de Janeiro fica no Brasil, na costa sudeste do país.\n",
      "\n",
      "\n",
      "O Rio de Janeiro fica localizado no Brasil, no litoral sudeste.\n"
     ]
    }
   ],
   "source": [
    "from myopenai import MyOpenAI\n",
    "\n",
    "chat = MyOpenAI(\"Aonde fica o Rio de Janeiro?\",\"text-davinci-003\",3,1000,1,\"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\")\n",
    "resposta = chat.callgpt()\n",
    "for x in resposta:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c970e-ff0b-4e6b-85f3-41bfedfcc141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
